"""
BERT-based Loyalty Analyzer
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π BERT –º–æ–¥–µ–ª–∏
"""

import torch
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Tuple, List
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')


class BertLoyaltyAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ BERT –º–æ–¥–µ–ª–∏
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω—É—é –¥—Ä—É–≥–æ–º –Ω–∞ 600 —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö
    """

    def __init__(self,
                 model_path: str = "Golden-apple-loyalty/models_binary_fixed_v2",
                 threshold: float = 0.718):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞

        Args:
            model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π BERT –º–æ–¥–µ–ª–∏
            threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (0.718 = –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)
        """
        self.model_path = Path(model_path)
        self.threshold = threshold
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # –†–∞–∑–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        self.threshold_high = 0.718    # –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
        self.threshold_medium = 0.55   # –°—Ä–µ–¥–Ω—è—è
        self.threshold_low = 0.40      # –ù–∏–∑–∫–∞—è (–¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π)

        self.model = None
        self.tokenizer = None
        self._model_loaded = False

    def load_model(self) -> bool:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ BERT –º–æ–¥–µ–ª–∏

        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞ BERT –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}...")

            if not self.model_path.exists():
                print(f"[ERROR] –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
                return False

            self.tokenizer = AutoTokenizer.from_pretrained(str(self.model_path))
            self.model = AutoModelForSequenceClassification.from_pretrained(str(self.model_path))
            self.model.to(self.device)
            self.model.eval()

            print(f"[OK] BERT –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
            self._model_loaded = True
            return True

        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        return self._model_loaded or self.model_path.exists()

    def _prepare_text(self, row: pd.Series) -> str:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ pros, cons, comment)

        Args:
            row: –°—Ç—Ä–æ–∫–∞ DataFrame

        Returns:
            –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        text_parts = []

        for field in ['pros', 'cons', 'comment']:
            if field in row and pd.notna(row[field]):
                value = str(row[field]).strip()
                if value:
                    text_parts.append(value)

        text = ' '.join(text_parts)

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
        if not text or len(text) < 10:
            return "–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞"

        return text

    def predict_batch(self,
                     texts: List[str],
                     batch_size: int = 32) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∞—Ç—á–∞ —Ç–µ–∫—Å—Ç–æ–≤

        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞

        Returns:
            –ú–∞—Å—Å–∏–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π [0, 1]
        """
        if not self._model_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ load_model() —Å–Ω–∞—á–∞–ª–∞")

        all_probs = []

        for i in tqdm(range(0, len(texts), batch_size),
                     desc="BERT –∞–Ω–∞–ª–∏–∑",
                     unit="batch"):
            batch_texts = texts[i:i+batch_size]

            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = self.tokenizer(
                batch_texts,
                truncation=True,
                padding=True,
                max_length=256,
                return_tensors='pt'
            ).to(self.device)

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏ (–±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)
                if logits.shape[-1] == 1:
                    # –û–¥–∏–Ω –≤—ã—Ö–æ–¥ - –∏—Å–ø–æ–ª—å–∑—É–µ–º sigmoid
                    probs = torch.sigmoid(logits).squeeze(-1).cpu().numpy()
                elif logits.shape[-1] == 2:
                    # –î–≤–∞ –≤—ã—Ö–æ–¥–∞ - –±–µ—Ä—ë–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1 (–ª–æ—è–ª—å–Ω—ã–π)
                    probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()
                else:
                    # Fallback
                    probs = torch.softmax(logits, dim=-1).max(dim=-1)[0].cpu().numpy()

            all_probs.extend(probs)

        return np.array(all_probs)

    def analyze_dataframe(self,
                         df: pd.DataFrame,
                         batch_size: int = 32) -> pd.DataFrame:
        """
        –ê–Ω–∞–ª–∏–∑ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame

        Args:
            df: DataFrame —Å –æ—Ç–∑—ã–≤–∞–º–∏
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏:
            - bert_loyalty_prob: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ [0, 1]
            - bert_loyalty_high: –ª–æ—è–ª—å–Ω—ã–π –ø–æ —Å—Ç—Ä–æ–≥–æ–º—É –ø–æ—Ä–æ–≥—É (0.718)
            - bert_loyalty_medium: –ª–æ—è–ª—å–Ω—ã–π –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –ø–æ—Ä–æ–≥—É (0.55)
            - bert_loyalty_low: –ª–æ—è–ª—å–Ω—ã–π –ø–æ –º—è–≥–∫–æ–º—É –ø–æ—Ä–æ–≥—É (0.40)
        """
        if not self._model_loaded:
            if not self.load_model():
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å BERT –º–æ–¥–µ–ª—å")
                return df

        df = df.copy()

        print(f"–ê–Ω–∞–ª–∏–∑ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ BERT –¥–ª—è {len(df):,} –æ—Ç–∑—ã–≤–æ–≤...")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
        texts = df.apply(self._prepare_text, axis=1).tolist()

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        probabilities = self.predict_batch(texts, batch_size=batch_size)

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ DataFrame
        df['bert_loyalty_prob'] = probabilities
        df['bert_loyalty_high'] = probabilities >= self.threshold_high
        df['bert_loyalty_medium'] = probabilities >= self.threshold_medium
        df['bert_loyalty_low'] = probabilities >= self.threshold_low

        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—Å—Ä–µ–¥–Ω–∏–π –ø–æ—Ä–æ–≥)
        df['bert_loyalty_class'] = df['bert_loyalty_high'].map({
            True: 'loyal',
            False: 'not_loyal'
        })

        print(f"[OK] BERT –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
        print(f"   –õ–æ—è–ª—å–Ω—ã—Ö (—Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ >={self.threshold_high}): "
              f"{df['bert_loyalty_high'].sum():,} ({df['bert_loyalty_high'].mean()*100:.1f}%)")
        print(f"   –õ–æ—è–ª—å–Ω—ã—Ö (—Å—Ä–µ–¥–Ω–∏–π –ø–æ—Ä–æ–≥ >={self.threshold_medium}): "
              f"{df['bert_loyalty_medium'].sum():,} ({df['bert_loyalty_medium'].mean()*100:.1f}%)")

        return df

    def calculate_product_stats(self,
                                df: pd.DataFrame,
                                min_reviews: int = 100) -> pd.DataFrame:
        """
        –†–∞—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º (–∫–∞–∫ —É –¥—Ä—É–≥–∞)

        Args:
            df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ BERT –∞–Ω–∞–ª–∏–∑–∞
            min_reviews: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–¥—É–∫—Ç–∞

        Returns:
            DataFrame —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º
        """
        if 'bert_loyalty_prob' not in df.columns:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ analyze_dataframe()")

        if 'product_name' not in df.columns:
            print("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ product_name –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return pd.DataFrame()

        print(f"\n[INFO] –†–∞—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º (–º–∏–Ω–∏–º—É–º {min_reviews} –æ—Ç–∑—ã–≤–æ–≤)...")

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º
        product_stats = df.groupby('product_name').agg({
            'bert_loyalty_prob': ['count', 'mean', 'std'],
            'bert_loyalty_high': 'sum',
            'bert_loyalty_medium': 'sum',
            'bert_loyalty_low': 'sum'
        })

        # Flatten column names
        product_stats.columns = [
            'total_reviews',
            'avg_bert_prob',
            'std_bert_prob',
            'loyal_high',
            'loyal_medium',
            'loyal_low'
        ]

        product_stats = product_stats.reset_index()

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—Ç–∑—ã–≤–æ–≤
        product_stats = product_stats[product_stats['total_reviews'] >= min_reviews].copy()

        # –†–∞—Å—á—ë—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        product_stats['loyalty_rate_high'] = product_stats['loyal_high'] / product_stats['total_reviews']
        product_stats['loyalty_rate_medium'] = product_stats['loyal_medium'] / product_stats['total_reviews']
        product_stats['loyalty_rate_low'] = product_stats['loyal_low'] / product_stats['total_reviews']

        # Z-score (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞–∫ —É –¥—Ä—É–≥–∞)
        global_loyalty_rate = product_stats['loyal_high'].sum() / product_stats['total_reviews'].sum()

        product_stats['z_score'] = (
            (product_stats['loyalty_rate_high'] - global_loyalty_rate) /
            np.sqrt(global_loyalty_rate * (1 - global_loyalty_rate) / product_stats['total_reviews'])
        )

        # –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –±–∞–ª–ª (–∫–∞–∫ –Ω–∞ IMDb)
        C = global_loyalty_rate
        m = product_stats['total_reviews'].median()

        product_stats['bayesian_score'] = (
            (product_stats['total_reviews'] / (product_stats['total_reviews'] + m)) * product_stats['loyalty_rate_high'] +
            (m / (product_stats['total_reviews'] + m)) * C
        )

        # –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
        product_stats['percentile_rank'] = product_stats['loyalty_rate_high'].rank(pct=True) * 100

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è (–∫–∞–∫ —É –¥—Ä—É–≥–∞)
        def categorize_z_score(z):
            if z >= 2:
                return "üöÄ –í—ã–¥–∞—é—â–∏–π—Å—è"
            elif z >= 1:
                return "üìà –í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ"
            elif z >= -1:
                return "üìä –°—Ä–µ–¥–Ω–∏–π"
            elif z >= -2:
                return "‚ö†Ô∏è –ù–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ"
            else:
                return "üî• –ü—Ä–æ–±–ª–µ–º–Ω—ã–π"

        product_stats['relative_category'] = product_stats['z_score'].apply(categorize_z_score)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ z-score
        product_stats = product_stats.sort_values('z_score', ascending=False)

        print(f"[OK] –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(product_stats)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
        print(f"   –°—Ä–µ–¥–Ω—è—è –ª–æ—è–ª—å–Ω–æ—Å—Ç—å: {global_loyalty_rate:.1%}")
        print(f"   –õ—É—á—à–∏–π –ø—Ä–æ–¥—É–∫—Ç (z-score): {product_stats.iloc[0]['z_score']:.2f}")

        return product_stats

    def get_statistics(self, df: pd.DataFrame) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ BERT –∞–Ω–∞–ª–∏–∑—É

        Args:
            df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        if 'bert_loyalty_prob' not in df.columns:
            return {}

        stats = {
            'total_reviews': len(df),
            'avg_probability': df['bert_loyalty_prob'].mean(),
            'median_probability': df['bert_loyalty_prob'].median(),
            'std_probability': df['bert_loyalty_prob'].std(),
            'loyal_high': {
                'count': int(df['bert_loyalty_high'].sum()),
                'percent': df['bert_loyalty_high'].mean() * 100
            },
            'loyal_medium': {
                'count': int(df['bert_loyalty_medium'].sum()),
                'percent': df['bert_loyalty_medium'].mean() * 100
            },
            'loyal_low': {
                'count': int(df['bert_loyalty_low'].sum()),
                'percent': df['bert_loyalty_low'].mean() * 100
            }
        }

        return stats


def compare_with_keyword_method(df: pd.DataFrame) -> pd.DataFrame:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ BERT –∞–Ω–∞–ª–∏–∑–∞ —Å keyword-based –º–µ—Ç–æ–¥–æ–º

    Args:
        df: DataFrame —Å –æ–±–æ–∏–º–∏ —Ç–∏–ø–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        DataFrame —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    required_cols = ['bert_loyalty_prob', 'loyalty_score']

    if not all(col in df.columns for col in required_cols):
        print("‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
        return pd.DataFrame()

    comparison = pd.DataFrame({
        'metric': ['–°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å/score', '–ú–µ–¥–∏–∞–Ω–∞', '–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'],
        'BERT': [
            df['bert_loyalty_prob'].mean(),
            df['bert_loyalty_prob'].median(),
            df['bert_loyalty_prob'].std()
        ],
        'Keyword': [
            df['loyalty_score'].mean(),
            df['loyalty_score'].median(),
            df['loyalty_score'].std()
        ]
    })

    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è
    corr = df['bert_loyalty_prob'].corr(df['loyalty_score'])

    print("\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤:")
    print(comparison.to_string(index=False))
    print(f"\n–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –º–µ—Ç–æ–¥–∞–º–∏: {corr:.3f}")

    return comparison


if __name__ == "__main__":
    # –¢–µ—Å—Ç
    print("BERT Loyalty Analyzer - Test")
    print("=" * 60)

    analyzer = BertLoyaltyAnalyzer()

    if analyzer.is_available():
        print("[OK] BERT –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞")

        # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_df = pd.DataFrame({
            'pros': [
                '–û—Ç–ª–∏—á–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç, –∫—É–ø–ª—é –µ—â—ë!',
                '–ù–æ—Ä–º–∞–ª—å–Ω–æ',
                '–£–∂–∞—Å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ'
            ],
            'cons': ['', '–î–æ—Ä–æ–≥–æ–≤–∞—Ç–æ', '–í—Å—ë –ø–ª–æ—Ö–æ'],
            'comment': [
                '–†–µ–∫–æ–º–µ–Ω–¥—É—é –≤—Å–µ–º, –±—É–¥—É –ø–æ–∫—É–ø–∞—Ç—å —Å–Ω–æ–≤–∞',
                '–û–±—ã—á–Ω—ã–π —Ç–æ–≤–∞—Ä',
                '–ë–æ–ª—å—à–µ –Ω–µ –∫—É–ø–ª—é'
            ],
            'product_name': ['–ü—Ä–æ–¥—É–∫—Ç –ê', '–ü—Ä–æ–¥—É–∫—Ç –ë', '–ü—Ä–æ–¥—É–∫—Ç –í']
        })

        print(f"\n–¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ {len(test_df)} –æ—Ç–∑—ã–≤–∞—Ö...")

        result = analyzer.analyze_dataframe(test_df)

        print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(result[['product_name', 'bert_loyalty_prob', 'bert_loyalty_class']])

        stats = analyzer.get_statistics(result)
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {stats['avg_probability']:.3f}")
        print(f"  –õ–æ—è–ª—å–Ω—ã—Ö (—Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥): {stats['loyal_high']['count']} ({stats['loyal_high']['percent']:.1f}%)")
    else:
        print("[ERROR] BERT –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        print(f"   –û–∂–∏–¥–∞–µ–º—ã–π –ø—É—Ç—å: Golden-apple-loyalty/models_binary_fixed_v2")
